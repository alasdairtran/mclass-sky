{
 "metadata": {
  "name": "",
  "signature": "sha256:eb65ce5d84eacc02ed83396878742e93d3671d4b8fa5d5eab2495b2d6545e3be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data Processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "HTML(open(\"styles/stylesheet.css\", \"r\").read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<link href='<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,700|Droid+Serif:400,700,400italic|Open+Sans:400italic,700italic,400,700' rel='stylesheet' type='text/css'>\n",
        "\n",
        "<style>\n",
        "\tbody {\n",
        "\t\tfont-family: 'Open Sans', sans-serif;\n",
        "\t}\n",
        "    \n",
        "    \n",
        "    /* limit cell width\n",
        "\tdiv.cell { \n",
        "\t\tmax-width: 1000px;\n",
        "\t\tmargin-left: auto;\n",
        "\t\tmargin-right: auto;\n",
        "\t} */\n",
        "    \n",
        "    /* More space between Markdown bullet points */\n",
        "\t#notebook li { \n",
        "\t\tmargin-top: 0.5em;\n",
        "\t} \n",
        "\n",
        "\t/* draw border around running cells */\n",
        "\tdiv.cell.border-box-sizing.code_cell.running { \n",
        "\t\tborder-width: thin;\n",
        "\t\tborder-style: solid;\n",
        "\t\tborder-color: red;\n",
        "\t\tborder-radius: 10px;\n",
        "\t}\n",
        "\n",
        "\t/* Put a solid color box around each cell and its output, visually linking\n",
        "    them together */\n",
        "\tdiv.cell.code_cell {\n",
        "\t\tborder-radius: 10px; /* rounded borders */\n",
        "\t\tpadding: 1em;\n",
        "\t}\n",
        "\n",
        "\t/* Markdown cells */\n",
        "\tdiv.text_cell_render {\n",
        "        background: #fff;\n",
        "        color: #444;\n",
        "        font-family: 'Open Sans', sans-serif;\n",
        "        line-height: 1.75;\n",
        "\t}\n",
        "    \n",
        "\t/* Formatting code in markdown cells */\n",
        "\tdiv.rendered_html code {\n",
        "\t\tfont-family: 'Source Code Pro', monospace;\n",
        "        line-height: 1.5;\n",
        "\t}\n",
        "    \n",
        "\t/* Formatting for header cells */\n",
        "    .text_cell_render h1, .text_cell_render h2, .text_cell_render h3,\n",
        "    .text_cell_render h4, .text_cell_render h5, .text_cell_render h6 {\n",
        "        font-family: 'Droid Serif', serif;\n",
        "        display: block;\n",
        "        font-weight: normal;\n",
        "    }\n",
        "    \n",
        "\t.text_cell_render h1 {\n",
        "\t\tfont-size: 250%;\n",
        "        text-align: center;\n",
        "\t\tcolor: #c65c3f;\n",
        "\t}\n",
        "    \n",
        "\t.text_cell_render h2 {\n",
        "        font-size: 200%;\n",
        "        color: #c65c3f;\n",
        "\t}\t\n",
        "\n",
        "\t.text_cell_render h3 {\n",
        "        font-size: 180%;\n",
        "        color: rgb(12,85,97);\n",
        "        font-weight: normal;\n",
        "\t}\n",
        "\n",
        "\t.text_cell_render h4 {\n",
        "        font-size: 150%;\n",
        "        color: rgb(12,85,97);\n",
        "\t}\n",
        "\n",
        "\t.text_cell_render h5 {\n",
        "        font-size: 110%;\n",
        "        color: #b2b888;\n",
        "        text-transform: uppercase;\n",
        "\t}\n",
        "\n",
        "\t.text_cell_render h6 {\n",
        "        font-size: 100%;\n",
        "\t\tcolor: #b2b888;\n",
        "        text-transform: uppercase;\n",
        "\t}\n",
        "\n",
        "\t.CodeMirror{\n",
        "\t\tfont-family: 'Inconsolata', monospace;\n",
        "        line-height: 1.5;\n",
        "\t}\n",
        "\n",
        "\t/* Hide the prompts, e.g. In[1], Out[1] */\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "\t\n",
        "\t/* Usage: <div class=warning> message here </div> */\n",
        "\t.warning{\n",
        "\t\tbackground-color: #fcf2f2;\n",
        "\t\tborder-color: #dFb5b4;\n",
        "\t\tborder-left: 5px solid #dfb5b4;\n",
        "\t\tpadding: 0.5em;\n",
        "\t}\n",
        "</style>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x55ea390>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook explains the script <a href=\"scripts/data_processing.py\" target=\"_blank\"> `scripts/data_processing.py`</a>, which consists of some useful functions we might want to call before feeding the data to the classifier."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Normalisation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.1. Zero Mean and Unit Variance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s normalise_z scripts/data_processing.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalise_z(features):\n",
      "    \"\"\" Normalise each feature to have zero mean and unit variance.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        features : array, shape = [n_samples, n_features]\n",
      "            Where each row is a sample point and each column is a feature.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        features_normalised : array, shape = [n_samples, n_features]\n",
      "    \"\"\"\n",
      "       \n",
      "    mu = np.mean(features, axis=0)\n",
      "    sigma = np.std(features, axis=0)\n",
      "    return (features - mu) / sigma\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.2. Unit Variance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s normalise_unit_var scripts/data_processing.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalise_unit_var(features):\n",
      "    \"\"\" Normalise each feature to have unit variance.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        features : array, shape = [n_samples, n_features]\n",
      "            Where each row is a sample point and each column is a feature.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        features_normalised : array, shape = [n_samples, n_features]\n",
      "    \"\"\"\n",
      "    \n",
      "    sigma = np.std(features, axis=0)\n",
      "    return features / sigma\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1.3. Unit Interval"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s normalise_01 scripts/data_processing.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalise_01(features):\n",
      "    \"\"\" Normalise each feature to unit interval.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        features : array, shape = [n_samples, n_features]\n",
      "            Where each row is a sample point and each column is a feature.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        features_normalised : array, shape = [n_samples, n_features]\n",
      "    \"\"\"\n",
      "    \n",
      "    minimum = np.min(features, axis=0)\n",
      "    maximum = np.max(features, axis=0)\n",
      "    return (features - minimum) / (maximum - minimum)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Balanced Training and Test Set Split"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For a dataset with an unequal numer of samples in each class, one useful procedure is to split the data into a training and a test set in such a way that the classes are balanced. This is implemented in the function `balanced_train_test_split()` below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s draw_random_sample scripts/data_processing.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def draw_random_sample(data, train_size, test_size, random_state=None):\n",
      "    \"\"\" Split the data into a train set and test set of a given size.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : DataFrame, shape = [n_samples, n_features]\n",
      "            Where each row is a sample point and each column is a feature.\n",
      "            \n",
      "        train_size : int\n",
      "            Number of sample points in the training set.\n",
      "            \n",
      "        test_size : int\n",
      "            Number of sample points in the test set.\n",
      "            \n",
      "        random_state : int, optional (default=None)\n",
      "            Random seed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        combined_train_test : DataFrame\n",
      "            Where each sample point (row) is indexed with either 'train' or 'test'.\n",
      "    \"\"\"\n",
      "    \n",
      "    m = len(data)    \n",
      "    \n",
      "    cv = ShuffleSplit(m, n_iter=1, train_size=train_size, test_size=test_size,\n",
      "                      random_state=random_state)\n",
      "\n",
      "    train, test = next(iter(cv))\n",
      "    train_set = data.iloc[train]\n",
      "    test_set = data.iloc[test]\n",
      "    \n",
      "    combined_train_test = pd.concat([train_set, test_set],\n",
      "                                    keys=['train', 'test'], names=['set'])\n",
      "    \n",
      "    return combined_train_test\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s balanced_train_test_split scripts/data_processing.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def balanced_train_test_split(data, features, target, train_size, test_size, random_state=None):\n",
      "    \"\"\" Split the data into a balanced training set and test set of some given size.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : DataFrame, shape = [n_samples, n_features]\n",
      "            Where each row is a sample point and each column is a feature.\n",
      "        \n",
      "        features : array, shape = [n_features]\n",
      "            The names of the columns in `data` that are used as feature vectors.\n",
      "            \n",
      "        target : str\n",
      "            The name of the column in `data` that is used as the traget vector\n",
      "        \n",
      "        train_size : int\n",
      "            Number of sample points from each class in the training set.\n",
      "            \n",
      "        test_size : int\n",
      "            Number of sample points from each class in the test set.\n",
      "            \n",
      "        random_state : int, optional (default=None)\n",
      "            Random seed.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        X_train : array\n",
      "            The feature vectors (stored as columns) in the training set.\n",
      "            \n",
      "        X_test : array\n",
      "            The feature vectors (stored as columns) in the test set.\n",
      "            \n",
      "        y_train : array\n",
      "            The target vector in the training set.\n",
      "            \n",
      "        y_test : array\n",
      "            The target vector in the test set.\n",
      "    \"\"\"\n",
      "    \n",
      "    grouped = data.groupby(data[target])\n",
      "    train_test = grouped.apply(lambda x: draw_random_sample(x, train_size, test_size, random_state))\n",
      "    train_test = train_test.swaplevel(0, 1)\n",
      "    \n",
      "    X_train = train_test.loc['train', features].as_matrix()\n",
      "    X_test =  train_test.loc['test', features].as_matrix()\n",
      "    y_train = train_test.loc['train'][target].as_matrix()\n",
      "    y_test =  train_test.loc['test'][target].as_matrix()\n",
      "    \n",
      "    return X_train, X_test, y_train, y_test\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
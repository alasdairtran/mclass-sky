%%
%% Template chap2.tex
%%

\chapter{Experiment 1: Learning with Random Sampling}
\label{cha:expt1}

\section{Preparation of Data}


\begin{itemize}
	\item Preparing the SDSS dataset:
	 Obtain data from SkyServer via SQL query (see Appendix for code)
	 \item Preparing the VST ATLAS: Data specifically prepared by Christian Wolf
	\item Convert data to HDF Table for fast reading
\end{itemize}


\section{Experimental Protocol}
\label{sec:protocol1}

SDSS Colour Features
\begin{itemize}
	\item Convert magnitude features to colours. Reason: remove distance dependence.
	Use five colours and one r-band magnitudes -- a rule of thumb used by astronomers.
	Choose r-band since it captures the most light, hence hopefully we have a low
	signal-to-noise ratio
\end{itemize}
Comparing Three sets of reddening correction on SDSS
\begin{itemize}
	\item Split into balanced training set (600,000) and test set (300,000).
	\item Use random forest (fast and accurate) with 300 trees
	\item Compare recall maps and accuracy rates
\end{itemize}
Comparing three families of classifiers: shuffle split with 5 iterations, train size is
up to 300,000 and test size is 200,000.
\begin{itemize}
	\item Random Forest, Logistic Regression, and SVM
	\item Do a grid search to optimise hyperparameters
	\item Plot learning curve with random sampling
	\item Use linear decision boundaries in SVM and Logistic but transform features with
	degree 2 and 3 polynomial.
\end{itemize}
Run random forest on all 2.8 million labelled examples and predict proportion 
on the 800 million unlabelled data. Corrections are made for the potential misclassification.



\section{Results and Discussion}
\label{sec:results1}

\subsection{Comparison of Reddening Correction Sets}
No significant difference. Will use W14 set for reasons stated in \cite{wolf14}.
Here we present violin plots. See Appendix for more detailed breakdown
the recall map improvements. 


\begin{figure}[tbp]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/violin_reddening_correction}
	\caption[Accuracy rates with four reddening correction sets]{Comparing the
		accuracy rates using 4 correction sets.}
	\label{fig:reddeningviolin}
\end{figure}

\subsection{Learning Curves with Random Sampling}
Optimal Hyper-parameters for SDSS
\begin{itemize}
	\item SVM RBF: $C = 10 000$ and $\gamma = 0.001$.
	\item SVM Polynomial degree 2 with one-vs-rest strategy, squared hinge loss and L1-norm
	(giving us sparse solutions) and $C = 0.1$.
	\item Logistic degree 2 also with one-vs-rest strategy, L1-norm and $C=1$.
\end{itemize}
Learning Curves
\begin{itemize}
	\item Random forest is the fastest and most accurate
	\item Degree 3 polynomial transformation offers better results than degree 2, although
	both do level off after 100,000 examples.
	\item Logistic degree 3 was stopped early as it took too long to run.
\end{itemize}



\begin{figure}[p]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/sdss_grid_logistic}
	\caption[Heatmap of logistic regression's cross-valdiation accuracy in SDSS]{
		Heatmap of linear logistic regression's cross-valdiation accuracy in SDSS}
	\label{fig:sdss_grid_logistic}
\end{figure}

\begin{figure}[p]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/vstatlas_grid_logistic}
	\caption[Heatmap of logistic regression's cross-valdiation accuracy in VST ATLAS]{
		Heatmap of logistic regression's cross-valdiation accuracy in VST ATLAS}
	\label{fig:vstatlas_grid_logistic}
\end{figure}

\begin{figure}[p]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/sdss_grid_poly}
	\caption[Heatmap of linear SVM's cross-valdiation accuracy in SDSS]{
		Heatmap of linear SVM's cross-valdiation accuracy in SDSS}
	\label{fig:sdss_grid_poly}
\end{figure}

\begin{figure}[p]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/vstatlas_grid_poly}
	\caption[Heatmap of linear SVM's cross-valdiation accuracy in VST ATLAS]{
		Heatmap of linear SVM's cross-valdiation accuracy in VST ATLAS}
	\label{fig:vstatlas_grid_poly}
\end{figure}

\begin{figure}[p]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/4_expt1/sdss_grid_rbf}
	\caption[Heatmap of RBF SVM's cross-valdiation accuracy in SDSS]{
		Heatmap of RBF SVM's cross-valdiation accuracy in SDSS}
	\label{fig:sdss_grid_rbf}
\end{figure}

\begin{figure}[p]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/4_expt1/vstatlas_grid_rbf}
	\caption[Heatmap of RBF SVM's cross-valdiation accuracy in VST ATLAS]{
		Heatmap of RBF SVM's cross-valdiation accuracy in VST ATLAS}
	\label{fig:vstatlas_grid_rbf}
\end{figure}





\begin{figure}[p]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/sdss_learning_curves}
	\caption[Learning curves with random sampling in SDSS]{
		SDSS learning curves with random sampling.}
	\label{fig:sdss_learning_curves}
\end{figure}

\begin{figure}[p]
	\centering
	\includegraphics[width=\textwidth]{figures/4_expt1/vstatlas_learning_curves}
	\caption[Learning curves with random sampling in VST ATLAS]{
		VST ATLAS learning curves with random sampling.}
	\label{fig:vstatlas_learning_curves}
\end{figure}





\subsection{Class Proportion Estimation}
See Figure \ref{fig:forest} for predictions. Show confusion matrix, and
both uncorrected and corrected values.

\begin{figure}[p]
	\centering
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.73\textwidth]{figures/4_expt1/sdss_train_galaxies}
		\caption{The distribution of galaxies.}
		\label{fig:training_g}
	\end{subfigure}\\
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.73\linewidth]{figures/4_expt1/sdss_train_stars}
		\caption{The distribution of stars.}
		\label{fig:training_s}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.73\linewidth]{figures/4_expt1/sdss_train_quasars}
		\caption{The distribution of quasars.}
		\label{fig:training_q}
	\end{subfigure}
	\caption[Distribution map of labelled objects in the SDSS]{The distribution map of
		the 2.8 million labelled objects in the SDSS: Observe that the
		galaxies are mostly uniformly distributed in the survey, while the stars are not.
		We also do not have a lot of examples of quasars.}
	\label{fig:training_dist}
\end{figure}

\begin{figure}[p]
	\centering
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.75\textwidth]{figures/4_expt1/map_prediction_forest_galaxies}
		\caption{Distribution of galaxies.}
		\label{fig:random1}
	\end{subfigure}\\
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.75\linewidth]{figures/4_expt1/map_prediction_forest_stars}
		\caption{Distribution of stars.}
		\label{fig:random2}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.75\linewidth]{figures/4_expt1/map_prediction_forest_quasars}
		\caption{Distribution of quasars.}
		\label{fig:random3}
	\end{subfigure}
	\caption{Map of predicted labels using random forest.}
	\label{fig:forest}
\end{figure}


\begin{figure}[p]
	\centering
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.75\textwidth]{figures/4_expt1/map_recall_forest_all_Galaxy}
		\caption{Recall of galaxies.}
		\label{fig:map_recall_forest_all_Galaxy}
	\end{subfigure}\\
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.75\linewidth]{figures/4_expt1/map_recall_forest_all_Star}
		\caption{Recall of stars.}
		\label{fig:map_recall_forest_all_Star}
	\end{subfigure}
	\begin{subfigure}{\textwidth}
		\centering
		\includegraphics[width=0.75\linewidth]{figures/4_expt1/map_recall_forest_all_Quasar}
		\caption{Recall of quasars.}
		\label{fig:map_recall_forest_all_Quasar}
	\end{subfigure}
	\caption{Recall map of the random forest.}
	\label{fig:map_recall_forest_all}
\end{figure}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 

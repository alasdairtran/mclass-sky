% Preamble
\documentclass[11pt]{amsart}
\usepackage{mathtools}
\usepackage{amssymb,latexsym}
\usepackage{physics}
\usepackage{listings}
\usepackage{bm}
\usepackage[margin=1.4in]{geometry}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, % set true if you want colored links
    linktoc=all,     % set to all if you want both sections and subsections 
                     % linked
    linkcolor=blue,  % choose some color if you want links to stand out
}
\usepackage{parskip}

% Environments
\theoremstyle{definition}
\newtheorem{algorithm}{Algorithm}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem*{main}{Main Theorem}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\theoremstyle{remark}
\newtheorem*{notation}{Notation}

% Commands and operators
\newcommand{\ind}{\hspace*{0.5cm}}
\newcommand{\gap}{\hspace*{0.25cm}}
\newcommand*{\Cdot}{\raisebox{-0.25ex}{\scalebox{1.3}{$\cdot$}}}
\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\transpose}{\text{T}}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\domain}{dom}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\sign}{sign}

\begin{document}
\lstset{language=}
\pagestyle{plain}

\title{Notes}
\author{David Wu}

\maketitle

\tableofcontents

\section{Linear regression}\label{s:linear_regression}
    We first recall the standard linear regression model. The set up is as follows:
    \begin{itemize}
        \item $D$ input variables $x_1, \dots, x_D$ with additional dummy input variable $x_0 = 1$. We represent this as an input vector $\vect{x} = (x_0, \dots, x_D)^\transpose$.
        \item $M$ basis functions $\phi_1(\vect{x}), \dots, \phi_{M-1}(\vect{x})$ with additional dummy basis function $\phi_0(\vect{x}) = 1$. We represent this by the vector-valued function $\bm{\phi}(\vect{x}) = (\phi_0(\vect{x}), \dots, \phi_M(\vect{x}))^\transpose$. We may use the notation $\bm{\phi}(\vect{x}) = \bm{\phi}$ also.
        \item $M$ parameters $w_0, \dots, w_{M-1}$ where we $w_0$ is the bias parameter. We represent this by the vector $\vect{w} = (w_0, \dots, w_{M-1})$.
    \end{itemize}
    The model is then given by
    \begin{equation*}
        y(\vect{x}, \vect{w}) = \sum_{j=0}^{M-1} w_j \phi_j(\vect{x}) = \vect{w}^\transpose \bm{\phi}(\vect{x}).
    \end{equation*}
    We now consider finding the optimal parameter vector $\vect{w}$ for our model. Here we have:
    \begin{itemize}
        \item A training set with $N$ data points $\{(\bm{\phi}_n, t_n)\}_{n=1}^{N}$ where $t_n \in \mathbb{R}$ and $\bm{\phi}_n = \bm{\phi}(\vect{x}_n)$. (We've applied $\bm{\phi}$ to the original input data points $\{\vect{x}_n\}_{n=1}^{N}$.) We represent the target data points by the vector $\vect{t} = (t_1, \dots, t_N)^\transpose$.
        \item We introduce the notation $y_n = y(\bm{\phi}_n) = \vect{w}^\transpose \bm{\phi}_n$.
    \end{itemize}
    The optimal parameter vector $\vect{w}$ is the parameter vector $\vect{w}$ which minimizes the \emph{sum-of-squares} error function
    \begin{equation}\label{e:sum_of_squares}
        E(\vect{w}) = \frac{1}{2} \sum_{n=1}^{N} 
                       \{y_n - t_n\}^2.
    \end{equation}
\section{Logistic regression}\label{s:logistic_regression}
    % Useful notation for future use:
    % p(\mathcal{C}_1 | \bm{\phi})
    % p(\mathcal{C}_2 | \bm{\phi}) = 1 -  p(\mathcal{C}_1 | \bm{\phi})
    % -\ln{p(\vect{t} | \vect{w})}
    For logistic regression we start with the setup for linear regression (Section \ref{s:linear_regression}). The logistic regression model is then given by 
    \begin{equation*}
        y(\bm{\phi}) = \sigma(\vect{w}^\transpose \bm{\phi}),
    \end{equation*}
    where $\sigma$ is the logistic sigmoid function defined by
    \begin{equation*}
        \sigma(a) = \frac{1}{1 + \exp(-a)}.
    \end{equation*}
    This function has the useful property
    \begin{equation*}
        \dv{\sigma}{a} = \sigma(1 - \sigma).
    \end{equation*}
    
    We now consider finding the optimal parameter vector $\vect{w}$ for our model. Here we have:
    \begin{itemize}
        \item A training set with $N$ data points $\{(\bm{\phi}_n, t_n)\}_{n=1}^{N}$ where $t_n \in \{0, 1\}$ and $\bm{\phi}_n = \bm{\phi}(\vect{x}_n)$. (We've applied $\bm{\phi}$ to the original input data points $\{\vect{x}_n\}_{n=1}^{N}$.) We represent the target data points by the vector $\vect{t} = (t_1, \dots, t_N)^\transpose$.
        \item We introduce the notation $y_n = y(\bm{\phi}_n) = \sigma(\vect{w}^\transpose \bm{\phi}_n)$.
    \end{itemize}
    The optimal parameter vector $\vect{w}$ is the parameter vector $\vect{w}$ which minimizes the \emph{cross-entropy} error function
    \begin{equation}\label{e:cross_entropy}
        E(\vect{w}) =  - \sum_{n=1}^{N} 
                       \{t_n \ln y_n + (1 - t_n)\ln(1 - y_n)\}.
    \end{equation}
    For solving this minimization problem, the gradient of the error function is useful. It is given by
    \begin{equation*}
        \nabla E(\vect{w}) = \sum_{i=1}^{N} (y_n - t_n)\bm{\phi}_n.
    \end{equation*}

\section{Regularization: linear regression and logistic regression}
    If a model overfits the training data, it may not generalize well to new examples. Here we describe one approach to reduce overfitting. 

    Let us denote both the sum-of-squares error function (Equation \ref{e:sum_of_squares}) and cross-entropy error function (Equation \ref{e:cross_entropy} introduced for linear regression and logistic regression, respectively, by $E_D(\vect{w})$. We refer to $E_D(\vect{w})$ as the \emph{data-dependent} error function. The overall error function we consider is
    \begin{equation*}
        E(\vect{w}) = E_D(\vect{w}) + \lambda E_W(\vect{w}),
    \end{equation*}
    where we call $E_W(\vect{w})$ the regularization term and $\lambda$ the regularization coefficient. 

    There are many choices for $E_W(\vect{w})$. A simple (and common) choice is the sum-of-squares of the elements of the weight vector $\vect{w}$
    \begin{equation*}
        E_W(\vect{w}) = \frac{1}{2}\vect{w}^\transpose \vect{w}.
    \end{equation*}
    The gradient of this quadratic regularizer with respect to $\vect{w}$ is
    \begin{equation*}
        \nabla E_W(\vect{w}) = \vect{w}.
    \end{equation*}

\section{Convex optimization}
    \subsection{Optimization problems}
        In this section we recall some of the basic terminology and definitions used to discuss optimization problems. We use the notation
        \begin{equation}\label{e:opt_problem}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) \\
            & \text{subject to} && f_i(x) \leq 0, \gap i = 1, \dots, m \\
            &                   && h_i(x) = 0, \gap i = 1, \dots, p
            \end{aligned}
        \end{equation}
        to denote the \emph{optimization problem} of finding an $x$ that minimizes $f_0(x)$ among all $x$ that satisfy the conditions $f_i(x) \leq 0, \gap i = 1, \dots, m$ and $h_i(x) = 0, \gap i = 1, \dots, p$. We have the following terminology and definitions:
        \begin{itemize}
            \item $x \in \mathbb{R}^n$ is the \emph{optimization variable}.
            \item $f_0: \mathbb{R}^n \to \mathbb{R}$ is the \emph{objective} or \emph{cost function}.
            \item $f_i(x) \leq 0$ are the \emph{inequality constraints} and $f_i(x)$ are the \emph{inequality constraint functions}.
            \item $h_i(x) = 0$ are the \emph{equality constraints} and $h_i(x)$ are the \emph{equality constraint functions}. 
            \item The \emph{domain} $\mathcal{D}$ of the optimization problem \eqref{e:opt_problem} is the set of points for which the objective and all constraint functions are defined. 
            \item A point $x \in D$ is \emph{feasible} if it satisfies all constraints $f_i(x) \leq 0$ and $h_i(x) = 0$. The set of all feasible points is called the \emph{feasible} or \emph{constraint set}. We say the problem \eqref{e:opt_problem} is \emph{feasible} if a feasible point exists and \emph{infeasible} otherwise.
            \item The \emph{optimal value} of the problem \eqref{e:opt_problem} is
                  $p^\star \coloneqq \inf \{ f_0(x) \;|\; \text{feasible points } x \}$.
            \item The point $x^\star$ is an \emph{optimal point}, that is, solves the problem \eqref{e:opt_problem}, if $x^\star$ is feasible and $f_0(x^\star) = p^\star$. The set of all optimal points is the \emph{optimal set}. 
            \item A point $x$ is \emph{$\epsilon$-suboptimal} if it is feasbile and $f_0(x) \leq p^\star + \epsilon$. The set of all $\epsilon$-suboptimal points is called the \emph{$\epsilon$-suboptimal set}.
        \end{itemize} 

   \subsection{Convex optimization problems}
        In this section we recall some of the basic terminology and definitions used to discuss convex optimization problems. A \emph{convex optimization problem} is an optimization problem of the form 
        \begin{equation}\label{e:convex_opt_problem}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) \\
            & \text{subject to} && f_i(x) \leq 0, \gap i = 1, \dots, m \\
            &                   && a_i^\transpose x = b_i, \gap i = 1, \dots, p
            \end{aligned}
        \end{equation}
        where $f_0, \dots, f_m$ are convex functions. 

        The problems of most interest to us are convex optimization problems of the form  
        \begin{equation}\label{e:convex_opt_problem_of_interest}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) \\
            & \text{subject to} && f_i(x) \leq 0, \gap i = 1, \dots, m
            \end{aligned}
        \end{equation}
        where $f_0, \dots, f_m$ are convex functions. 

    \subsection{Subgradients}
        In this section we recall some of the basics of subgradients. Recall that a vector $g \in \mathbb{R}^n$ is a \emph{subgradient} of $f: \mathbb{R}^n \to \mathbb{R}$ at $x \in \domain f$ if 
        \begin{equation}\label{d:subgrad}
            f(z) \geq f(x) + g^\transpose(z-x)
        \end{equation}
        for all $z \in \domain f$.

        \begin{theorem}[Existence of subgradients]\label{t:existence_of_subgrads}
            If $f$ is convex and $x \in \interior \domain f$, then the subdifferential $\partial f(x)$ is nonempty and bounded 
        \end{theorem}

        \begin{theorem}[Subgradients of differentiable functions]\label{t:subgrads_of_diff_functions}
            If $f$ is convex and differentiable at $x$, then $\partial f(x) = \{ \nabla f(x)\}$.
        \end{theorem}

        \begin{theorem}[Minimums and subgradients]\label{t:minimums_and_subgrads}
            A point $x^\star$ is a minimizer of a function $f$ if and only if $f$ is subdifferentiable at $x^\star$ and $0 \in \partial f(x^\star)$.
        \end{theorem}

\section{Descent methods}
    \subsection{The set-up}
        In this section we discuss methods for solving the unconstrained optimization problem 
        \begin{equation*}\label{e:unconstrained_opt_problem}
            \min_{\domain f} f(x)
        \end{equation*}
        where 
        \begin{itemize}
            \item $f: \mathbb{R}^n \to \mathbb{R}$ is convex and twice continuously differentiable.
            \item We assume the problem is solvable, i.e., there exists an optimal point $x^\star$, and denote the optimal value by $p^\star \coloneqq f(x^\star)$.
        \end{itemize} 
        Now, as $f$ is differentiable and convex, a point $x^\star$ is optimal if and only if $\nabla f(x^\star) = 0$, and so the problem \eqref{e:unconstrained_opt_problem} is equivalent to finding a solution to $\nabla f(x) = 0$, a set of $n$ equations in $n$ variables. In general, solving $\nabla f(x) = 0$ analytically is impossible so we aim to find an approximate solution via a iterative algorithm. That is, an algorithm that computes a sequence of points $x^{(0)}, x^{(1)}, \dots \in \domain f$ where $f(x^{(k)}) \to p^\star$ as $k \to \infty$, called  a \emph{minimizing sequence} for the problem \eqref{e:unconstrained_opt_problem}, and terminates when $f(x^{(k)}) - p^\star \leq \epsilon$, where $\epsilon > 0$ is a given \emph{tolerance}. 
    \subsection{Descent methods}
        In this section we introduce the \emph{conceptual} (or \emph{general}) \emph{descent method} which we can see as the template on which many common minimization algorithms are based. It is as follows:

        \begin{algorithm}[Conceptual descent method]
        \label{a:conceptual_descent_method}\mbox{}\\
            \ind \textbf{given} a starting point $x \in \domain f$\\
            \ind \textbf{repeat} \\
            \ind\ind 1. Determine a descent direction $\Delta x$. \\
            \ind\ind 2. \emph{Line search.} Choose a step size $t > 0$. \\
            \ind\ind 3. \emph{Update.} $x \coloneqq x + t \Delta x$. \\
            \ind \textbf{until} stopping criterion is satisfied. \\
        \end{algorithm} 
    \subsection{Backtracking line search}
         \begin{algorithm}[Backtracking line search]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} a descent direction $\Delta x$ for $f$ at $x \in \domain f$, $\alpha \in (0, 0.5), \beta \in (0, 1).$ \\
            \ind $t \coloneqq 1$. \\
            \ind \textbf{while} $f(x + t\Delta x) > f(x) + \alpha t \Delta f(x)^\transpose \Delta x$ \\
            \ind\ind $t \coloneqq \beta t$.
        \end{algorithm}        

    \subsection{Newton's method}
        Here we discuss \emph{Newton's method}.

        \begin{algorithm}[Newton's method]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} a starting point $x \in \domain f$, tolerance $\epsilon > 0.$ \\
            \ind \textbf{repeat} \\
            \ind\ind 1. \emph{Compute the Newton step and decrement.} \\
            \ind\ind\ind $\Delta x_{nt} \coloneqq -\nabla^2 f(x)^{-1} \nabla f(x)$ \\
            \ind\ind\ind $\lambda^2 \coloneqq \nabla f(x)^\transpose \nabla^2 f(x)^{-1} \nabla f(x).$ \\
            \ind\ind 2. \emph{Stopping criterion.} \textbf{quit} if $\lambda^2/2 \leq \epsilon.$\\
            \ind\ind 3. \emph{Line search.} Choose step size $t$ by backtracking line search. \\
            \ind\ind 4. \emph{Update.} $x \coloneqq x + t\Delta x_{nt}.$ \\
        \end{algorithm}

\section{Duality}
    In this section we discuss duality. We consider a standard optimization problem
    \begin{equation}\label{e:opt_problem}
        \begin{aligned}
        & {\text{minimize}} && f_0(x) \\
        & \text{subject to} && f_i(x) \leq 0, \gap i = 1, \dots, m \\
        &                   && h_i(x) = 0, \gap i = 1, \dots, p
        \end{aligned}
    \end{equation}
    with variable $x \in \mathbb{R}^n$. We assume its domain $\mathcal{D}$ is non-empty and denote the optimal value by $p^\star$. To clarify, we do not assume it is convex.  


\section{Interior-point methods} 
    \subsection{Inequality constrained convex optimization problems and their approximations}
        In this section we discuss \emph{interior-point methods} for solving inequality constrained convex optimization problems. Specifically, those with the form
        \begin{equation}\label{e:ineq_constrd_cvx_opt_problem}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) \\
            & \text{subject to} && f_i(x) \leq 0, \gap i = 1, \dots, m \\
            &                   && Ax = b
            \end{aligned}
        \end{equation}
        where $f_0, \dots, f_m: \mathbb{R}^n \to \mathbb{R}$ are convex and twice continuously differentiable, and $A \in \mathbb{R}^{p \times n}$ with $\rank A = p < n$. We assume that the problem is solvable, i.e., a optimal $x^\star$ exists and write $p^\star \coloneqq f_0(x^\star)$. We assume also that the problem is strictly feasible, i.e., there exists $x \in \mathcal{D}$ that satisfies $f_i(x)<0$ for $i = 1, \dots, m$ and $Ax = b$.

        The approach is this: approximately formulate the inequality constrained problem \eqref{e:ineq_constrd_cvx_opt_problem} as an equality constrained problem to which Newton's method can be applied.

        Now, making the inequality constraints implicit we have that \eqref{e:ineq_constrd_cvx_opt_problem} is equivalent to the problem
        \begin{equation}\label{e:impl_ineq_constrd_cvx_opt_problem}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) + \sum_{i=1}^{m}{I_{-}(f_i(x))} \\
            & \text{subject to} && Ax = b.
            \end{aligned}
        \end{equation}
        This is close to what we want, but its objective function is not (in general) differentiable, so Newton's method cannot be applied.

        Therefore, approximating $I_{-}$ by the function
        \begin{equation}
            \widehat{I}_{-} \coloneqq -\left(\frac{1}{t}\right)\log(-u)
        \end{equation}
        where $t > 0$ is a given parameter (observe that the approximation to $I_{-}$ increases as $t$ increases) we may may re-write \eqref{e:ineq_constrd_cvx_opt_problem} as
        \begin{equation}\label{e:ineq_constrd_cvx_opt_problem_approx_equiv}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) + \sum_{i=1}^{m}{\widehat{I}_{-}(f_i(x))} =
            f_0(x) + \sum_{i=1}^{m}{-\left(\frac{1}{t}\right)\log(-f_i(x))}  \\
            & \text{subject to} && Ax = b.
            \end{aligned}
        \end{equation}
        From the following observations it is clear this is what we want:
        \begin{itemize}
            \item $\widehat{I}_{-}$ is convex and nondecreasing.
            \item $\widehat{I}_{-}$ is twice differentiable and closed.
         \end{itemize} 
        For reasons of convenience the equivalent problem
        \begin{equation}\label{e:ineq_constrd_cvx_opt_problem_approx}
            \begin{aligned}
            & {\text{minimize}} && 
            tf_0(x) + \phi(x)  \\
            & \text{subject to} && Ax = b.
            \end{aligned}
        \end{equation}
        will be preferred. Now, this of course is a approximation of \eqref{e:ineq_constrd_cvx_opt_problem}. The question then, is how close this approximation is.  

        For the purposes of answering this let us assume that for each $t>0$ there is a unique solution $x^\star(t)$ of the problem \eqref{e:ineq_constrd_cvx_opt_problem_approx}, attained by, say, Newton's method. We call the set $\{x^\star(t) \;|\; t>0 \}$ the \emph{central path} and the points within it the \emph{central points}. We do not justify why this is the case, but the important fact is this:
        \begin{equation*}
            f_0(x^\star(t)) - p^\star \leq \frac{m}{t},
        \end{equation*}
        i.e., $x^\star(t)$ is no more than $\frac{m}{t}$-suboptimal.

        Therefore, if we want to solve the problem \eqref{e:ineq_constrd_cvx_opt_problem} to $\epsilon$ accuracy then we simply put $t \coloneqq \frac{m}{\epsilon}$ and solve the equality constrained problem 
        \begin{equation}\label{e:ineq_constrd_cvx_opt_problem_epsilon_approx}
            \begin{aligned}
            & {\text{minimize}} && 
            \left(\frac{m}{\epsilon}\right)f_0(x) + \phi(x)  \\
            & \text{subject to} && Ax = b.
            \end{aligned}
        \end{equation}
        using Newton's method. We call this the \emph{unconstrained minimization method}. For a number of practical reasons, this method is rarely used, and instead the \emph{barrier method} is used.

    \subsection{The barrier method}
        The barrier method is as follows
         \begin{algorithm}[Barrier method]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} strictly feasible $x$, $t \coloneqq t^{(0)} > 0$, $\mu > 1$, tolerance $\epsilon > 0$ \\
            \ind $k \coloneqq 0$. \\
            \ind \textbf{repeat} \\
            \ind\ind 1. \emph{Centering step.} \\
            \ind\ind\ind Compute $x^\star(t)$ by solving \eqref{e:ineq_constrd_cvx_opt_problem_approx} via Newton's method starting at $x$. \\
            \ind\ind 2. \emph{Update.} $x \coloneqq x^\star(t)$ \\
            \ind\ind 3. \emph{Stopping criterion.} \textbf{quit} if $\frac{m}{t} < \epsilon$. \\
            \ind\ind 4. \emph{Increase $t$.} $t \coloneqq \mu t$
        \end{algorithm}

        With regards to implementation we have the following points
        \begin{itemize}
            \item \emph{Choice of $\mu$.} Values of around 10 to 20 work well. 
        \end{itemize}

    \subsection{Feasbility and the basic phase I method}
        The barrier method requires a strictly feasible starting point $x^{(0)}$. If such a point is not known, the barrier method is preceded by a preliminary stage, called \emph{phase I}, in which such a point is computed (or the constraints are found to be infeasible).

        Suppose we have a set of inequalities and equalities in the variables $x \in \mathbb{R}^n$,
        \begin{equation*}
            f_i(x) \leq 0, i = 1, \dots, m, \qquad Ax = b
        \end{equation*}
        where $f_i: \mathbb{R}^n \to \mathbb{R}$ are convex with continuous second derivatives. We assume that we are given a point $x^{(0)}$ in the domain of all $f_i$ with $Ax^{(0)} = b$. To find a strictly feasible solution of these inequalities and equalities (or determine that none exists) we form the following optimization problem:
        \begin{equation}\label{e:phase_i}
            \begin{aligned}
            & {\text{minimize}} && s  \\
            & \text{subject to} && f_i(x) \leq s, i = 1, \dots, m \\
            & && Ax = b
            \end{aligned}
        \end{equation}
        in the variables $x \in \mathbb{R}^n, s \in \mathbb{R}$ (or equivalently $(x, s) \in \mathbb{R}^n \times \mathbb{R}$). If we have found a point $x$ that solves this and $s < 0$ we are done.

        This problem is always strictly feasible as we can choose $x^{(0)}$ as our starting point for $x$ and then we simply put $s > \max_{i=1, \dots, m}{f_i(x^{(0)})}$. To solve \eqref{e:phase_i} we apply the barrier method and call this problem the \emph{phase I optimization problem} associated with \eqref{e:phase_i}. 

        The details of applying the barrier method are as follows. We re-write \eqref{e:phase_i} to match \eqref{e:ineq_constrd_cvx_opt_problem} as 
        \begin{equation}\label{e:phase_i_ineq_constrd_cvx_opt_problem}
            \begin{aligned}
            & {\text{minimize}} && s  \\
            & \text{subject to} && f_i(x) - s \leq 0, i = 1, \dots, m \\
            & && Ax = b.
            \end{aligned}
        \end{equation}
        Matching \eqref{e:impl_ineq_constrd_cvx_opt_problem} this is then equivalent to
        \begin{equation}\label{e:phase_i_impl_ineq_constrd_cvx_opt_problem}
            \begin{aligned}
            & {\text{minimize}} && s + \sum_{i=1}^{m}{I_{-}(f_i(x)-s)} \\
            & \text{subject to} && Ax = b,
            \end{aligned}
        \end{equation}
        which can then be approximated by 
        \begin{equation}\label{e:phase_i_ineq_constrd_cvx_opt_problem_approx_equiv}
            \begin{aligned}
            & {\text{minimize}} && 
            s + \sum_{i=1}^{m}{-\left(\frac{1}{t}\right)\log(s-f_i(x))}  \\
            & \text{subject to} && Ax = b,
            \end{aligned}
        \end{equation}
        or equivalently
        \begin{equation}\label{e:phase_i_ineq_constrd_cvx_opt_problem_approx}
            \begin{aligned}
            & {\text{minimize}} && 
            ts + \sum_{i=1}^{m}{-\log(s-f_i(x))}  \\
            & \text{subject to} && Ax = b.
            \end{aligned}
        \end{equation}

        The barrier method is then
         \begin{algorithm}[Barrier method applied to phase I optimization problem]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} strictly feasible $z = (x, s) \in \mathbb{R}^n \times \mathbb{R}$, $t \coloneqq t^{(0)} > 0$, $\mu > 1$ \\
            \ind $k \coloneqq 0$. \\
            \ind \textbf{repeat} \\
            \ind\ind 1. \emph{Centering step.} \\
            \ind\ind\ind Compute $z^\star(t) = (x^\star(t), s^\star(t))$ by solving \eqref{e:ineq_constrd_cvx_opt_problem_approx} via Newton's method starting at $z$. \\
            \ind\ind 2. \emph{Update.} $z \coloneqq z^\star(t)$ \\
            \ind\ind 3. \emph{Stopping criterion.} \textbf{quit} if $s < 0$. \\
            \ind\ind 4. \emph{Increase $t$.} $t \coloneqq \mu t$
        \end{algorithm}


\section{Cutting plane methods}
    \subsection{The basic conceptual cutting-plane/localization algorithm}
        In this section we describe and present the basic conceptual cutting-plane (or localization) algorithm. The initial set-up is as follows:
        \begin{itemize}
            \item A target set $X$.
            \item A set of linear inequalities $Cz \preceq d$ with $C \in \mathbb{R}^{q \times n}$ which is satisfied by all $z \in X$. Equivalently, we have a polyhedron $\mathcal{P}_0 \coloneqq \{ z \:|\: Cz \preceq d\}$ with $X \subseteq \mathcal{P}_0$. 
        \end{itemize}
        The purpose of this algorithm is to find a point in a target set $X$ or determine $X$ is empty starting with the knowledge that $X$ is contained within a polyhedron $\mathcal{P}_0$. The algorithm does this by, at each iteration, cutting away an additional section of the polyhedron $\mathcal{P}_0$ until either a point in $X$ is found or nothing is left of $\mathcal{P}_0$, that is, $\mathcal{P}_0 = \emptyset$. The case of most interest to us is when the target set $X$ is the optimal set for the inequality constrained convex optimization problem \eqref{e:convex_opt_problem_of_interest} and $\mathcal{P}_0$ is some polyhedron that contains $X$.

        We begin by choosing a point $x^{(1)} \in \mathcal{P}_0$. We then query the oracle at $x^{(1)}$. If we have that $x^{(1)} \in X$ we quit. Otherwise, $x^{(1)} \not\in X$, so we find a cutting plane 
        \begin{equation*}
            a_1^{\transpose}z \leq b_1
        \end{equation*}
        where
        \begin{equation*}
            a_1^{\transpose}x^{(1)} \geq b_1.
        \end{equation*}
        That is, $x^{(1)}$ sits outside or on the boundary of this cutting plane. We then put 
        \begin{equation*}
            \mathcal{P}_1 \coloneqq \mathcal{P}_0 \cap \{z \:|\: a_1^{\transpose}z \leq b_1\}.
        \end{equation*}
        If $\mathcal{P}_1 = \emptyset$, we quit. Otherwise, $\mathcal{P}_1 \neq \emptyset$, and we repeat this procedure again by choosing a point $x^{(2)} \in \mathcal{P}_1$. In summary:
        \begin{algorithm}[Basic conceptual cutting-plane (or localization) algorithm]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} an initial polyhedron $\mathcal{P}_0 = \{z \:|\: Cz \preceq d\}$ known to contain $X$. \\
            \ind $k \coloneqq 0$. \\
            \ind \textbf{repeat} \\
            \ind\ind Choose a point $x^{k+1} \in \mathcal{P}_k$. \\
            \ind\ind Query the cutting-plane oracle at $x^{(k+1)}$. \\
            \ind\ind If the oracle determines that $x^{(k+1)} \in X$, quit. \\
            \ind\ind Else, update $\mathcal{P}_k$ by adding the new cutting-plane: $\mathcal{P}_{k+1} \coloneqq \mathcal{P}_k \cap \{z \:|\: a_{k+1}^\transpose z \leq b_{k+1} \}$. \\
            \ind\ind If $\mathcal{P}_{k+1} = \emptyset$, quit. \\
            \ind\ind $k \coloneqq k+1$.
        \end{algorithm}
        As noted, this algorithm is conceptual, it requires, in particular, specification of the following: 
        \begin{itemize}
            \item How to construct an appropriate cutting plane if it is determined that the query point $x^{(k+1)}$ for a given iteration $k$ is not in the target set $X$.
            \item How to generate the query point $x^{(k+1)}$ for each iteration $k$.
        \end{itemize}

    \subsection{Cutting planes for inequality constrained problems}
        In this section we describe how to construct cutting planes for the conceptual cutting plane algorithm (Algorithm \eqref{a:basic_conceptual_cp_alg}) when the target set $X$ is the optimal set for the inequality constrained convex optimization problem \eqref{e:convex_opt_problem_of_interest} and $P_0$ is some polyhedron that contains $X$.

        Suppose we have generated a query point $x$. We first check if $x$ is a feasible point. Suppose $x$ is not a feasible point. Then there exists some index $j \in \{1, \dots, m\}$ with $f_j(x) > 0$, that is, the $j$-th constraint has been violated. The cutting plane we will define comes from the following discussion. As $f_j$ is convex (we make the additional assumption $x \in \interior \domain f_j$) there exists some subgradient $g_j \in \partial f(x)$ (Theorem \ref{t:existence_of_subgrads}) with the defining property
        \begin{equation*}
            f_j(z) \geq f_j(x) + g_j^\transpose(z-x)
        \end{equation*}
        for all $z \in \domain f_j$. Therefore,
        \begin{equation*}
            f_j(x) + g^\transpose(z-x) > 0 \implies f_j(z) > 0, \text{ or equivalenty, }
            f_j(z) \leq 0 \implies f_j(x) + g^\transpose(z-x) \leq 0
        \end{equation*}
        for all $z \in \domain f$. That is all feasible points must satisfies $f_j(x) + g^\transpose(z-x) \leq 0$. So the cutting plane is defined to be all points $z$ that satisfy
        \begin{equation*}
            f_j(x) + g^\transpose(z-x) \leq 0.
        \end{equation*}
        Observe that substituting $x$ into this inequality reduces to $f_j(x) \leq 0$ but in actuality $f_j(x) > 0$, so therefore $x$ is not included in this cutting plane, as desired. 

        On the other hand, suppose $x$ is a feasible point. We choose any subgradient $g_0 \in \partial f_0(x)$. If $g_0 = 0$, then $x$ is optimal and we are done (Theorem \ref{t:minimums_and_subgrads}). So suppose $g_0 \neq 0$. Observe that if a point $z$ satisfies $g_0^\transpose(z-x) > 0$, then this implies $f_0(z) \geq f_0(x)$ by the defining inequality (Equation \eqref{d:subgrad}) of subgradients. That is, $z$ is not optimal. So in this case the cutting plane is defined to be all points $z$ that satisfy
        \begin{equation*}
            g_0^\transpose(z-x) \leq 0.
        \end{equation*}

\section{The analytic center cutting-plane method}
    \subsection{The algorithm}
        The analytic center cutting-plane method (ACCPM) is a cutting plane algorithm with both theoretical and practical applicability. For our purposes we specialise to convex optimization problems of the form 
        \begin{equation*}
            \begin{aligned}
            & {\text{minimize}} && f_0(x) \\
            & \text{subject to} && f_i(x) \leq 0, \gap i = 1, \dots, m
            \end{aligned}
        \end{equation*}
        where $f_0, \dots, f_m$ are convex functions. We introduce the ACCPM here, and will discuss details of the algorithm and its implementation in seperate sections, namely:
        \begin{itemize}
            \item How to construct an appropriate cutting plane if it is determined that the query point $x^{(k+1)}$ for a given iteration $k$ is not in the target set $X$.
            \item How to generate the query point $x^{(k+1)}$ for each iteration $k$.
        \end{itemize}
        For convenience of the reader we will review some of what has been discussed in previous sections. The ACCPM is as follows: 
        \begin{algorithm}[Analytic center cutting-plane method (ACCPM)]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} an initial polyhedron $\mathcal{P}_0 = \{z \:|\: Cz \preceq d\}$ known to contain $X$. \\
            \ind $k \coloneqq 0$. \\
            \ind \textbf{repeat} \\
            \ind\ind Compute $x^{(k+1)}$, the analytic center of $\mathcal{P}_k$. \\
            \ind\ind Query the cutting-plane oracle at $x^{(k+1)}$. \\
            \ind\ind If the oracle determines that $x^{(k+1)} \in X$, quit. \\
            \ind\ind Else, update $\mathcal{P}_k$ by adding the new cutting-plane: $\mathcal{P}_{k+1} \coloneqq \mathcal{P}_k \cap \{z \:|\: a_{k+1}^\transpose z \leq b_{k+1} \}$. \\
            \ind\ind If $\mathcal{P}_{k+1} = \emptyset$, quit. \\
            \ind\ind $k \coloneqq k+1$.
        \end{algorithm}
        In the algorithm $X$ is either the optimal set or $\epsilon$-suboptimal set, for some fixed $\epsilon > 0$, for the optimization problem.

    \subsection{Query point generation for the ACCPM: the analytic center}
        At each iteration $k$ the query point $x^{(k+1)}$ is given by the \emph{analytic center} of the inequalities that specify $\mathcal{P}_k$, which we discuss in this section. Consider the function,
        \begin{equation}
            \phi(x) = - \sum_{i=1}^{m+k}{\log{(b_i - a_i^\transpose x)}}
        \end{equation}
        with 
        \begin{equation}
            \domain \phi = \{x \;|\; a_i^\transpose x < b_i, i = 1, \dots, m, m+1, \dots, m+k\}
        \end{equation}
        called the \emph{logarithmic barrier} or \emph{log barrier} for (the inequalities which specify) the polyhedron $\mathcal{P}_k$. (We may simplify the constraint inequalities as $Ax \preceq b$.) The analytic center of the inequalities which specify the polyhedron $\mathcal{P}_k$ is then given by the solution of the problem 
        \begin{equation}\label{e:log_barrier_problem}
            \min_{\domain \phi} \phi.
        \end{equation}
        We will refer to this simply as the analytic center of $\mathcal{P}_k$ for convenience while acknowledging that $\mathcal{P}_k$ can be specified by (infinitely) many different choices of half planes and that this choice determines the solution of \eqref{e:log_barrier_problem}.

    \subsection{Computing the analytic center, phase I optimization and the Newton method}
        The approach we take in computing the analytic center in this section is as follows:
        \begin{enumerate}
            \item Use a phase I optimization method to find a point in $\domain \phi$.
            \item Use the standard Newton method to compute the analytic center.
        \end{enumerate}

        We first discuss the the phase I optimization problem that we must solve, that is, the problem
        \begin{equation}\label{e:phase_i_accpm}
            \begin{aligned}
            & {\text{minimize}} && s  \\
            & \text{subject to} && f_i(x) \coloneqq a_i^\transpose x - b_i \leq s, i = 1, \dots, m+k \\
            \end{aligned}
        \end{equation}

        Following \eqref{e:phase_i_ineq_constrd_cvx_opt_problem_approx} we can therefore approximate \eqref{e:phase_i_accpm} by the problem
        \begin{equation}\label{e:phase_i_accpm_approx}
            \begin{aligned}
            & {\text{minimize}} && 
            f_0(x, s)\coloneqq ts + \sum_{i=1}^{m+k}{-\log(s+b_i - a_i^\transpose x)}.
            \end{aligned}
        \end{equation}
        To solve this using the barrier method, we will need to use Newton's method. Therefore we will need the gradient of the objective $f_0(x, s)$ which is
        \begin{align*}
            &\nabla f_0(x, s)_i = \sum_{i=1}^{m+k} \frac{1}{s+b_i-a_i^\transpose x}a_i \text{, $i = 1, \dots, n$} \\ 
            &\nabla f_0(x, s)_{n+1} = t - \sum_{i=1}^{m+k} \frac{1}{s+b_i-a_i^\transpose x}. 
        \end{align*}

        At this point we recall the barrier method:
        \begin{algorithm}[Barrier method applied to phase I optimization problem]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} strictly feasible $z = (x, s) \in \mathbb{R}^n \times \mathbb{R}$, $t \coloneqq t^{(0)} > 0$, $\mu > 1$ \\
            \ind $k \coloneqq 0$. \\
            \ind \textbf{repeat} \\
            \ind\ind 1. \emph{Centering step.} \\
            \ind\ind\ind Compute $z^\star(t) = (x^\star(t), s^\star(t))$ by solving \eqref{e:ineq_constrd_cvx_opt_problem_approx} via Newton's method starting at $z$. \\
            \ind\ind 2. \emph{Update.} $z \coloneqq z^\star(t)$ \\
            \ind\ind 3. \emph{Stopping criterion.} \textbf{quit} if $s < 0$. \\
            \ind\ind 4. \emph{Increase $t$.} $t \coloneqq \mu t$
        \end{algorithm}

        Now, from our prior discussion we know that we need pick initial $x^{(0)}$ in the domain of all $f_i$ and then any initial $s > \max_{i=1, \dots, m}\{a_i^\transpose x - b_i\}$.

        We discuss the Newton method in the context of computing the analytic center. We give the Newton method applied to $\phi$
        \begin{algorithm}[Newton's method]
        \label{a:basic_conceptual_cp_alg}\mbox{}\\
            \ind \textbf{given} a starting point $x \in \domain \phi$, tolerance $\epsilon > 0.$ \\
            \ind \textbf{repeat} \\
            \ind\ind 1. \emph{Compute the Newton step and decrement.} \\
            \ind\ind\ind $\Delta x_{nt} \coloneqq -\nabla^2 \phi(x)^{-1} \nabla \phi(x)$ \\
            \ind\ind\ind $\lambda^2 \coloneqq \nabla \phi(x)^\transpose \nabla^2 \phi(x)^{-1} \nabla \phi(x).$ \\
            \ind\ind 2. \emph{Stopping criterion.} \textbf{quit} if $\lambda^2/2 \leq \epsilon.$\\
            \ind\ind 3. \emph{Line search.} Choose step size $t$ by backtracking line search. \\
            \ind\ind 4. \emph{Update.} $x \coloneqq x + t\Delta x_{nt}.$ \\
        \end{algorithm} 
        For the gradient and Hessian of $\phi$ we have
        \begin{align}
            &\nabla \phi(x) = \sum_{i=1}^{m+k} \frac{1}{b_i - a_i^\transpose x}a_i = A^\transpose d \\
            &\nabla^2 \phi(x) = \sum_{i=1}^{m+k} \frac{1}{(b_i - a_i^\transpose x)^2}a_i a_i^\transpose = A^\transpose \diag(d)^2 A
        \end{align}
        where for $d \in \mathbb{R}^{m+k}$ we have
        \begin{align*}
            d_i = \frac{1}{b_i - a_i^\transpose x}.
        \end{align*}
        Observe that since $x$ is strictly feasible, $d \succ 0$, which implies $\det(d) \neq 0$ 

    \subsection{Computing the analytic center and the infeasible start Newton method}
        The approach we take in computing the analytic center in this section is to use an infeasible start Newton method. The advantage of this approach is that we do not require the initial points and subsequent iterates to be feasible points. 

        Now, we re-write \eqref{e:log_barrier_problem} as
        \begin{equation*}
            \begin{aligned}
            & {\text{minimize}} && -\sum{i=1}^{m+k} \log{y_i} \\
            & \text{subject to} && y \coloneqq b - Ax
            \end{aligned}
        \end{equation*}

    \subsection{Stopping criterion}

\section*{Active Learning}
    In this section we discuss active learning and how its relation to cutting planes.
    \subsection*{The problem of interest}
        The problems we are considered with here are linear classification problems. The set up is as follows:
        \begin{itemize}
            \item We have a training sample $D = \{(x_n, y_n)\}_{n \in [N]}$ with $x_n \in \mathcal{X} = \mathbb{R}^n$ and $y_n \in \mathcal{Y} = \{-1, +1\}$.
            \item We are looking for a classification vector $w \in \mathcal{X}$ for the linear predictor 
            \begin{align*}
                f_w(x) = \sign(w \cdot x).
            \end{align*}
            \item In particular, we look for a classification vector from the version space
            \begin{align*}
                \mathcal{W}_0(D) = \{w \in \mathcal{X} \;|\; y_n(w \cdot x_n) \geq 0 \text{ for all } n \in [N] \},
            \end{align*}
            which means that $f_w(\cdot)$ makes no mistakes on $D$.
            \item We assume that $W_0(D)$ is not empty.
        \end{itemize}
        The problem can be summarized as 
        \begin{align*}
            \text{find } w \text{ s.t. } 
            \begin{cases} 
                w \in \mathcal{X} \\
                y_n(w \cdot x_n) \geq 0 \text{ for all } n \in [N]
            \end{cases}
        \end{align*}

    \subsection*{Another conceptual cutting plane algorithm and its application to linear classification problems.}

\renewcommand\refname{Bibliography}
\begin{thebibliography}{99}
    \bibitem[Bis06]{bishop_06} C. Bishop. \emph{Pattern Recognition and Machine Learning}. Springer, 2006.
    \bibitem[Boy08A] S. Boyd. \emph{Lecture 6 $|$ Convex Optimization II (Stanford)}. 2008. \url{https://youtu.be/N3vJOq5ZmKc}.
    \bibitem[Boy08B] S. Boyd. \emph{Lecture 7 $|$ Convex Optimization II (Stanford)}. 2008. \url{https://youtu.be/t0MmgkV4YrA}.
    \bibitem[BV04]{boyd_vandenberghe_04} S. Boyd and L. Vandenberghe. \emph{Convex Optimization}. Cambridge University Press, 2004.
    \bibitem[BVS08]{boyd_vandenberghe_skaf_08} S. Boyd, L. Vandenberghe and J. Skaf. \emph{Analytic Center Cutting-Plane Method}. 2008. \url{https://see.stanford.edu/materials/lsocoee364b/06-accpm_notes.pdf}.
    \bibitem[BV11]{boyd_vandenberghe_11} S. Boyd and L. Vandenberghe. \emph{Localization and Cutting-Plane Methods}. 2011. \url{http://web.stanford.edu/class/ee364b/lectures/localization_methods_notes.pdf}.
    \bibitem[BDV15]{boyd_duchi_vandenberghe_11} S. Boyd, J. Duchi and L. Vandenberghe. \emph{Subgradients}. 2015. \url{http://web.stanford.edu/class/ee364b/lectures/subgradients_notes.pdf}.
    \bibitem[NgA]{ng_a} A. Ng. \emph{CS229 Lecture Notes 1}. \url{http://cs229.stanford.edu/notes/cs229-notes1.pdf}.
    \bibitem[NgB]{ng_b} A. Ng. \emph{Machine Learning}. \url{https://www.coursera.org/learn/machine-learning}.
    \bibitem[ShaA]{shalizi_a} C. R. Shalizi. \emph{Advanced Data Analysis
    from an Elementary Point of View}. \url{http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV.pdf}. 
\end{thebibliography}

% Examples:
% \bibitem[AHU]{ahu} Aho, A.,\ Hopcroft, J.,\ and Ullman, J.\ (1976). {\em{The Design and Analysis of Computer Algorithms.}} Addison Wesley, Reading, Mass.

% \bibitem[AT]{AT} Auslander, L. and Tolmieri, R. (1979). Is Computing with the Fast Fourier Transform Pure or Applied Mathematics? {\em{Bulletin (New Series) of the AMS Vol. 1}} 847-897.

% [Lee03] John Lee, \emph{Introduction to Topological Manifolds}, Springer Science, New York, USA, 2003.

% [Rat06] John Ratcliffe, \emph{Foundations of Hyperbolic Manifolds}, Springer Science, New York, USA, 2006.

\end{document}
{
 "metadata": {
  "name": "",
  "signature": "sha256:f21dd5ace10dadcf821b7fbf5d287bb95f646c74cf67b24b14d318f59e497d24"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Performance Measures"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "HTML(open(\"styles/stylesheet.css\", \"r\").read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<link href='<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:400,700|Droid+Serif:400,700,400italic|Open+Sans:400italic,700italic,400,700' rel='stylesheet' type='text/css'>\n",
        "\n",
        "<style>\n",
        "\tbody {\n",
        "\t\tfont-family: 'Open Sans', sans-serif;\n",
        "\t}\n",
        "    \n",
        "    \n",
        "    /* limit cell width\n",
        "\tdiv.cell { \n",
        "\t\tmax-width: 1000px;\n",
        "\t\tmargin-left: auto;\n",
        "\t\tmargin-right: auto;\n",
        "\t} */\n",
        "    \n",
        "    /* More space between Markdown bullet points */\n",
        "\t#notebook li { \n",
        "\t\tmargin-top: 0.5em;\n",
        "\t} \n",
        "\n",
        "\t/* draw border around running cells */\n",
        "\tdiv.cell.border-box-sizing.code_cell.running { \n",
        "\t\tborder-width: thin;\n",
        "\t\tborder-style: solid;\n",
        "\t\tborder-color: red;\n",
        "\t\tborder-radius: 10px;\n",
        "\t}\n",
        "\n",
        "\t/* Put a solid color box around each cell and its output, visually linking\n",
        "    them together */\n",
        "\tdiv.cell.code_cell {\n",
        "\t\tborder-radius: 10px; /* rounded borders */\n",
        "\t\tpadding: 1em;\n",
        "\t}\n",
        "\n",
        "\t/* Markdown cells */\n",
        "\tdiv.text_cell_render {\n",
        "        background: #fff;\n",
        "        color: #444;\n",
        "        font-family: 'Open Sans', sans-serif;\n",
        "        line-height: 1.75;\n",
        "\t}\n",
        "    \n",
        "\t/* Formatting code in markdown cells */\n",
        "\tdiv.rendered_html code {\n",
        "\t\tfont-family: 'Source Code Pro', monospace;\n",
        "        line-height: 1.5;\n",
        "\t}\n",
        "    \n",
        "\t/* Formatting for header cells */\n",
        "    .text_cell_render h1, .text_cell_render h2, .text_cell_render h3,\n",
        "    .text_cell_render h4, .text_cell_render h5, .text_cell_render h6 {\n",
        "        font-family: 'Droid Serif', serif;\n",
        "        display: block;\n",
        "        font-weight: normal;\n",
        "    }\n",
        "    \n",
        "\t.text_cell_render h1 {\n",
        "\t\tfont-size: 250%;\n",
        "        text-align: center;\n",
        "\t\tcolor: #c65c3f;\n",
        "\t}\n",
        "    \n",
        "\t.text_cell_render h2 {\n",
        "        font-size: 200%;\n",
        "        color: #c65c3f;\n",
        "\t}\t\n",
        "\n",
        "\t.text_cell_render h3 {\n",
        "        font-size: 180%;\n",
        "        color: rgb(12,85,97);\n",
        "        font-weight: normal;\n",
        "\t}\n",
        "\n",
        "\t.text_cell_render h4 {\n",
        "        font-size: 150%;\n",
        "        color: rgb(12,85,97);\n",
        "\t}\n",
        "\n",
        "\t.text_cell_render h5 {\n",
        "        font-size: 110%;\n",
        "        color: #b2b888;\n",
        "        text-transform: uppercase;\n",
        "\t}\n",
        "\n",
        "\t.text_cell_render h6 {\n",
        "        font-size: 100%;\n",
        "\t\tcolor: #b2b888;\n",
        "        text-transform: uppercase;\n",
        "\t}\n",
        "\n",
        "\t.CodeMirror{\n",
        "\t\tfont-family: 'Inconsolata', monospace;\n",
        "        line-height: 1.5;\n",
        "\t}\n",
        "\n",
        "\t/* Hide the prompts, e.g. In[1], Out[1] */\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "\t\n",
        "\t/* Usage: <div class=warning> message here </div> */\n",
        "\t.warning{\n",
        "\t\tbackground-color: #fcf2f2;\n",
        "\t\tborder-color: #dFb5b4;\n",
        "\t\tborder-left: 5px solid #dfb5b4;\n",
        "\t\tpadding: 0.5em;\n",
        "\t}\n",
        "</style>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x4eb75f8>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook explains the script <a href=\"scripts/classifier_performance.py\" target=\"_blank\"> `scripts/performance_measures.py`</a>, which contains various functions that evaluate the performance of a classifier."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some notations:\n",
      "\n",
      "* $C$ is the confusion matrix, where entry $C_{ij}$ is the number of objects in class $i$ but have been as class $j$,\n",
      "* $m_i$ is the number of objects in class $i$: $m_i = \\sum_j C_{ij}$,\n",
      "* $m$ is the total sample size: $m = \\sum_i m_i$,\n",
      "* $k$ is the number of classes."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Contents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. [Naive Accuracy](#s1)\n",
      "2. [Balanced Accuracy](#s2)\n",
      "    1. [Convolution](#s2.1)\n",
      "    2. [Expected Balanced Accuracy](#s2.2)\n",
      "    3. [Distriubtion of Balanced Accuracy](#s2.3)\n",
      "3. [Recall](#s3)\n",
      "4. [Precision](#s4)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<a id='s1'></a>\n",
      "1. Naive Accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One simple way to evaluate the overall performance of a classifier is to compute the naive accuracy rate, which is simply the total fraction of objects that have been correctly classified:\n",
      "\\begin{aligned}\n",
      "    \\text{Naive Accuracy Rate} = \\dfrac{\\sum_i C_{ii}}{m}\n",
      "\\end{aligned}\n",
      "\n",
      "This is implemented in the function **`naive_accuracy()`**:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s naive_accuracy scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def naive_accuracy(confusion):\n",
      "    \"\"\" Compute the naive accuracy rate.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        confusion : array, shape = [n_classes, n_classes]\n",
      "            Where entry c_{ij} is the number of observations in class i but\n",
      "            are classified as class j.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        naive_accuracy : float\n",
      "    \"\"\"\n",
      "    \n",
      "    return p.trace(confusion) / np.sum(confusion)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<a id='s2'></a>\n",
      "2. Balanced Accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, if the dataset is imbalanced, this measure would not work well. A better approach is to use the <a href=\"http://ong-home.my/papers/brodersen10post-balacc.pdf\" target=\"_blank\">posterior balanced accuracy</a>. Let $A_i$ be the accuracy rate of class $i$:\n",
      "\\begin{aligned}\n",
      "    A_i = \\dfrac{C_{ii}}{m_i}\n",
      "\\end{aligned}\n",
      "\n",
      "Before running a classifier, we know nothing of its performance, so we can assume the accuracy rate follows a flat prior distribution. In particular, the Beta distribution with parameters $\\alpha = \\beta = 1$ (i.e. a uniform distriubtion) seems appropriate here:\n",
      "\\begin{aligned}\n",
      "    A_i \\sim Beta(1, 1) \\qquad \\forall i\n",
      "\\end{aligned}\n",
      "\n",
      "Given an accuracy rate $A_i$ for each class $i$, the number of correct predictions in class $i$ will follow a Binomial distribution with $A_i$ as the probability of success:\n",
      "\\begin{aligned}\n",
      "    \\big( C_{ii} \\mid A_i \\big) \\sim Bin\\big(m_i, A_i\\big)  \\qquad \\forall i\n",
      "\\end{aligned}\n",
      "\n",
      "In Bayesian terms, this is our likelihood. Now we know that with respect to a Binomial likelihood, the Beta distribution is conjugate to itself. Thus the posterior distribution of $A_i$ will also be Beta with parameters:\n",
      "\\begin{aligned}\n",
      "    \\big( A_i \\mid C_{ii} \\big) \\sim Beta \\big( 1 + C_{ii}, 1 + m_i - C_{ii} \\big) \\qquad \\forall i\n",
      "\\end{aligned}\n",
      "\n",
      "Here's a helper function that extracts the beta paremeters form a confusion matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s get_beta_parameters scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_beta_parameters(confusion):\n",
      "    \"\"\" Extract the beta parameters from a confusion matrix.\n",
      "    \n",
      "        Parameter\n",
      "        ---------\n",
      "        confusion : array, shape = [n_classes, n_classes]\n",
      "            Where entry c_{ij} is the number of observations in class i but\n",
      "            are classified as class j.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        parameters: array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution\n",
      "            that corresponds to class i.\n",
      "    \"\"\"\n",
      "    alphas, betas = [], []\n",
      "    \n",
      "    # number of classes\n",
      "    k = len(confusion)\n",
      "    \n",
      "    for i in range(k):\n",
      "        # alpha is 1 plus the number of objects that are correctly classified\n",
      "        alphas.append(1 + confusion[i, i])\n",
      "        \n",
      "        # beta is 1 plus the number of objects that are incorrectly classified\n",
      "        betas.append(1 + confusion.sum(axis=1)[i] - confusion[i, i])\n",
      "    \n",
      "    return list(zip(alphas, betas))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<a id='s2.1'></a>\n",
      "2.1. Convultion"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way to define the balanced accuracy $A$ is to take the average of the individual accuracy rates $A_i$:\n",
      "\\begin{aligned}\n",
      "    A = \\dfrac{1}{k} \\sum_i A_i\n",
      "\\end{aligned}\n",
      "\n",
      "We call $\\big( A \\mid C \\big)$ the posterior balanced accuracy. One nice feature of this measure is that it's a probability distribution (instead of a simple point estimate). This allows us to construct confidence intervals, etc. And even though there is no closed form solution for the density function of $\\big( A \\mid C \\big)$, we can still compute it by performing the <a href=\"https://en.wikipedia.org/wiki/Probability_density_function#Sums_of_independent_random_variables\" target=\"_blank\">convolution</a> $k$ times. This can easily be done in Python. Here's an implementation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s convolve_betas scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convolve_betas(parameters, res=0.001):\n",
      "    \"\"\" Convolves k Beta distributions.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        parameters : array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
      "        \n",
      "        res : float (default=0.001)\n",
      "            The precision of the resulting convolution, measured as step size in\n",
      "            the support.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        convolution : array, shape = [k / res]\n",
      "            The resulting convultion of the k Beta distributions, given the\n",
      "            specified presicion `res`.\n",
      "    \"\"\"\n",
      "    \n",
      "    # number of convolution\n",
      "    k = len(parameters)\n",
      "    \n",
      "    # sum of three probabilities ranges from 0 to k\n",
      "    x = np.arange(0, k+res, res)\n",
      "    \n",
      "    # compute the individual beta pdfs\n",
      "    pdfs = []\n",
      "    for par in parameters:\n",
      "        pdfs.append(beta.pdf(x, par[0], par[1]))\n",
      "        \n",
      "    # convolve k times\n",
      "    convolution = pdfs[0]\n",
      "    for i in range(1, k):\n",
      "        convolution = np.convolve(convolution, pdfs[i])\n",
      "        \n",
      "    # reduce to the [0, k] support\n",
      "    convolution = convolution[0:len(x)]\n",
      "    \n",
      "    # normalise so that all values sum to (1 / res)\n",
      "    convolution = convolution / (sum(convolution) * res)\n",
      "    \n",
      "    return convolution\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<a id='s2.2'></a>\n",
      "2.2. Expected Balanced Accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have just approximated the density of the sum of $k$ Beta distributions. The next step is to present our results. One measure we can report is the expected value of the posterior balanced accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s balanced_accuracy_expected scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def balanced_accuracy_expected(confusion):\n",
      "    \"\"\" Compute the expected value of the posterior balanced accuracy.\n",
      "    \n",
      "        Parameter\n",
      "        ---------\n",
      "        confusion : array, shape = [n_classes, n_classes]\n",
      "            Where entry c_{ij} is the number of observations in class i but\n",
      "            are classified as class j.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        bal_accuracy_expected: float\n",
      "    \"\"\"\n",
      "    \n",
      "    # extract beta distribution parameters from the confusion matrix \n",
      "    parameters = get_beta_parameters(confusion)\n",
      "    \n",
      "    # convolve the distributions and compute the expected value\n",
      "    res = 0.001\n",
      "    x = np.arange(0, k + res, res)\n",
      "    bal_accuracy = convolve_betas(parameters, res)\n",
      "    bal_accuracy_expected = (1/k) * np.dot(x, bal_accuracy * res)\n",
      "    \n",
      "    return bal_accuracy_expected\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "<a id='s2.3'></a>\n",
      "2.3. Distribution of Balanced Accuracy"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also construct an empirical distribution for the posterior expected accuracy. First we need to compute the pdf of the sum of beta distributions $\\sum_i A_i$, given a subset $x$ of the domain."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s beta_sum_pdf scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def beta_sum_pdf(x, parameters, res=0.001):\n",
      "    \"\"\" Compute the pdf of the sum of beta distributions.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array\n",
      "            A subset of the domain where we want evaluate the pdf.\n",
      "            \n",
      "        parameters : array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
      "        \n",
      "        res : float, optional (default=0.001)\n",
      "            The precision of the convolution, measured as step size in\n",
      "            the support.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        y : array\n",
      "            The pdf evaulated at x.\n",
      "    \"\"\"\n",
      "    \n",
      "    convolution = convolve_betas(parameters, res)\n",
      "    \n",
      "    # convert x into a numpy array if it's not already\n",
      "    x = np.array(x)\n",
      "    \n",
      "    # initialise the y vector\n",
      "    y = np.array([np.nan] * len(x))\n",
      "    \n",
      "    # upper bound of support\n",
      "    k = len(parameters)\n",
      "    \n",
      "    # set y to 0 if we're outside support\n",
      "    y[(x < 0) | (x > k)] = 0\n",
      "    \n",
      "    # index in convolution vector that is closest to x\n",
      "    c_index = np.int_(x / res)\n",
      "    \n",
      "    # fill in y vector\n",
      "    y[np.isnan(y)] = convolution[c_index[np.isnan(y)]]\n",
      "    \n",
      "    return y\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However we're interested in the average of the accuracy rates, $A = \\dfrac{1}{k} \\sum_i A_i = \\dfrac{1}{k} A_T$. We can rewrite the pdf of $A$ as:\n",
      "    \\begin{align}\n",
      "    F_A (a) &= \\mathbb{P} (A \\leq a) \\\\\n",
      "            &= \\mathbb{P}\\bigg( \\dfrac{1}{k} \\sum_i A_i \\leq a \\bigg) \\\\\n",
      "            &= \\mathbb{P}\\bigg( \\sum_i A_i \\leq ka \\bigg) \\\\\n",
      "            &= F_{A_T}(ka)\n",
      "    \\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Differnetiating with respect to $a$, we'd get:\n",
      "    \\begin{align}\n",
      "    f_A(a) &= \\dfrac{\\partial}{\\partial a} F_A(a) \\\\\n",
      "           &= \\dfrac{\\partial}{\\partial a} F_{A_T}(ka) \\\\\n",
      "           &= k \\cdot f_{A_T} (ka)\n",
      "    \\end{align}\n",
      "\n",
      "Here's the Python implementation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s beta_avg_pdf scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def beta_avg_pdf(x, parameters, res=0.001):\n",
      "    \"\"\" Compute the pdf of the average of the k beta distributions.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array\n",
      "            A subset of the domain where we want evaluate the pdf.\n",
      "            \n",
      "        parameters : array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
      "        \n",
      "        res : float, optional (default=0.001)\n",
      "            The precision of the convolution, measured as step size in\n",
      "            the support.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        y : array\n",
      "            The pdf evaulated at x.\n",
      "    \"\"\"\n",
      "    \n",
      "    k = len(parameters)\n",
      "    y = beta_sum_pdf(k * np.array(x), parameters, res)\n",
      "    y = y * k\n",
      "    \n",
      "    return y\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To make a violin plot of the posterior balanced accuracy, we need to run a Monte Carlo simulation, which requires us to have the inverse cdf of $A$. Let's approximate the integral of the pdf using the trapezium rule."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s beta_sum_cdf,beta_avg_cdf,beta_avg_inv_cdf scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def beta_sum_cdf(x, parameters, res=0.001):\n",
      "    \"\"\" Compute the cdf of the sum of the k beta distributions.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array\n",
      "            A subset of the domain where we want evaluate the cdf.\n",
      "            \n",
      "        parameters : array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
      "        \n",
      "        res : float, optional (default=0.001)\n",
      "            The precision of the convolution, measured as step size in\n",
      "            the support.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        y : array\n",
      "            The cdf evaulated at x.\n",
      "    \"\"\"\n",
      "    \n",
      "    convolution = convolve_betas(parameters, res)\n",
      "    \n",
      "    y = np.array([np.nan] * len(x))\n",
      "    for i in range(len(x)):\n",
      "        c_index = int(round(x[i] / res))\n",
      "        if c_index <= 0:\n",
      "            y[i] = 0\n",
      "        elif c_index >= len(convolution):\n",
      "            y[i] = 1\n",
      "        else:\n",
      "            y[i] = trapz(convolution[:c_index+1], dx=res)\n",
      "    \n",
      "    return y\n",
      "\n",
      "def beta_avg_cdf(x, parameters, res=0.001):\n",
      "    \"\"\" Compute the cdf of the average of the k beta distributions.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array\n",
      "            A subset of the domain where we want evaluate the cdf.\n",
      "            \n",
      "        parameters : array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
      "        \n",
      "        res : float, optional (default=0.001)\n",
      "            The precision of the convolution, measured as step size in\n",
      "            the support.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        y : array\n",
      "            The cdf evaulated at x.\n",
      "    \"\"\"\n",
      "    \n",
      "    x = np.array(x)\n",
      "    k = len(parameters)\n",
      "    y = beta_sum_cdf(k * x, parameters, res)\n",
      "    \n",
      "    return y\n",
      "\n",
      "def beta_avg_inv_cdf(y, parameters, res=0.001):\n",
      "    \"\"\" Compute the inverse cdf of the average of the k beta distributions.\n",
      "    \n",
      "        Parameters\n",
      "        ----------\n",
      "        y : float\n",
      "            A float between 0 and 1 (the range of the cdf)\n",
      "            \n",
      "        parameters : array of tuples\n",
      "            Each tuple (alpha_i, beta_i) is the parameters of a Beta distribution.\n",
      "        \n",
      "        res : float, optional (default=0.001)\n",
      "            The precision of the convolution, measured as step size in\n",
      "            the support.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        x : float\n",
      "            the inverse cdf of y\n",
      "    \"\"\"\n",
      "    \n",
      "    return brentq(lambda x: beta_avg_cdf([x], parameters, res)[0] - y, 0, 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<a id='s3'></a>\n",
      "3. Recall"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also compute the recall of each class. The recall of class $i$ is defined as:\n",
      "\\begin{aligned}\n",
      "    \\text{Recall}_i = \\dfrac{C_{ii}}{\\sum_j C_{ij}}\n",
      "\\end{aligned}\n",
      "\n",
      "Intuitively, the recall measures a classifier's ability to find all the positive samples (and hence minimising the number of false negatives)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s recall scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def recall(confusion):\n",
      "    \"\"\" Compute the recall from a confusion matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        confusion : array, shape = [n_classes, n_classes]\n",
      "            Where entry c_{ij} is the number of observations in class i but\n",
      "            are classified as class j.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        recalls : array\n",
      "            A list of recalls, one for each class.\n",
      "    \"\"\"\n",
      "    \n",
      "    # number of classes\n",
      "    k = len(confusion)\n",
      "\n",
      "    # extract recall from confusion matrix\n",
      "    recalls = []\n",
      "    for i in range(k):\n",
      "        recalls.append(confusion[i, i] / confusion.sum(axis=1)[i])\n",
      "\n",
      "    return recalls\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "<a id='s4'></a>\n",
      "4. Precision"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another useful measure is the precision. The precision of class $i$ is defined as:\n",
      "\\begin{aligned}\n",
      "    \\text{Precision}_i = \\dfrac{C_{ii}}{\\sum_j C_{ji}}\n",
      "\\end{aligned}\n",
      "\n",
      "Intuitively, the precision measures a classifier's ability to minimise the number of false positives."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load -s precision scripts/performance_measures.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def precision(confusion, classes, classifiers):\n",
      "    \"\"\" Compute the precision from a confusion matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        confusion : array, shape = [n_classes, n_classes]\n",
      "            Where entry c_{ij} is the number of observations in class i but\n",
      "            are classified as class j.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        precisions : array\n",
      "            A list of precisions, one for each class.\n",
      "    \"\"\"\n",
      "\n",
      "    # number of classes\n",
      "    k = len(confusion)\n",
      "\n",
      "    # extract recall from confusion matrix\n",
      "    precisions = []\n",
      "    for i in range(k):\n",
      "        precisions.append(confusion[i, i] / confusion.sum(axis=0)[i])\n",
      "\n",
      "    return precisions\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}